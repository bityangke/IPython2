{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-09-29 15:11:48,317] Making new env: CartPole-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find old network weights\n",
      "episode:  0 Evaluation Average Reward: 12.8\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "saved_networks/network-dqn-1000.tempstate13356802897360842560\n\t [[Node: save/save = SaveSlices[T=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/save/tensor_names, save/save/shapes_and_slices, Variable, Variable/Adam, Variable/Adam_1, Variable_1, Variable_1/Adam, Variable_1/Adam_1, Variable_2, Variable_2/Adam, Variable_2/Adam_1, Variable_3, Variable_3/Adam, Variable_3/Adam_1, beta1_power, beta2_power)]]\nCaused by op u'save/save', defined at:\n  File \"/Users/holazhai/anaconda/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/Users/holazhai/anaconda/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/traitlets/config/application.py\", line 596, in launch_instance\n    app.start()\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-b8bbfdc69533>\", line 200, in <module>\n    main()\n  File \"<ipython-input-1-b8bbfdc69533>\", line 154, in main\n    agent = DQN(env)\n  File \"<ipython-input-1-b8bbfdc69533>\", line 40, in __init__\n    self.saver = tf.train.Saver()\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 861, in __init__\n    restore_sequentially=restore_sequentially)\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 517, in build\n    save_tensor = self._AddSaveOps(filename_tensor, vars_to_save)\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 213, in _AddSaveOps\n    save = self.save_op(filename_tensor, vars_to_save)\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 165, in save_op\n    tensor_slices=[vs.slice_spec for vs in vars_to_save])\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/io_ops.py\", line 179, in _save\n    tensors, name=name)\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 438, in _save_slices\n    data=data, name=name)\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 710, in apply_op\n    op_def=op_def)\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2317, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1239, in __init__\n    self._traceback = _extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b8bbfdc69533>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-b8bbfdc69533>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    163\u001b[0m                         \u001b[0;31m# Define reward for agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                         \u001b[0mreward_agent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperceive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m                         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-b8bbfdc69533>\u001b[0m in \u001b[0;36mperceive\u001b[0;34m(self, state, action, reward, next_state, done)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_Q_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mtrain_Q_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-b8bbfdc69533>\u001b[0m in \u001b[0;36mtrain_Q_network\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# save network every 1000 iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_step\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'saved_networks/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'network'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-dqn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0megreedy_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/holazhai/anaconda/lib/python2.7/site-packages/tensorflow/python/training/saver.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph)\u001b[0m\n\u001b[1;32m   1073\u001b[0m     model_checkpoint_path = sess.run(\n\u001b[1;32m   1074\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_tensor_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1075\u001b[0;31m         {self.saver_def.filename_tensor_name: checkpoint_file})\n\u001b[0m\u001b[1;32m   1076\u001b[0m     \u001b[0mmodel_checkpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m     self._MaybeDeleteOldCheckpoints(model_checkpoint_path,\n",
      "\u001b[0;32m/Users/holazhai/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 710\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    711\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/holazhai/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 908\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/holazhai/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 958\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    959\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/holazhai/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    976\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: saved_networks/network-dqn-1000.tempstate13356802897360842560\n\t [[Node: save/save = SaveSlices[T=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/save/tensor_names, save/save/shapes_and_slices, Variable, Variable/Adam, Variable/Adam_1, Variable_1, Variable_1/Adam, Variable_1/Adam_1, Variable_2, Variable_2/Adam, Variable_2/Adam_1, Variable_3, Variable_3/Adam, Variable_3/Adam_1, beta1_power, beta2_power)]]\nCaused by op u'save/save', defined at:\n  File \"/Users/holazhai/anaconda/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/Users/holazhai/anaconda/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/traitlets/config/application.py\", line 596, in launch_instance\n    app.start()\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-b8bbfdc69533>\", line 200, in <module>\n    main()\n  File \"<ipython-input-1-b8bbfdc69533>\", line 154, in main\n    agent = DQN(env)\n  File \"<ipython-input-1-b8bbfdc69533>\", line 40, in __init__\n    self.saver = tf.train.Saver()\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 861, in __init__\n    restore_sequentially=restore_sequentially)\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 517, in build\n    save_tensor = self._AddSaveOps(filename_tensor, vars_to_save)\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 213, in _AddSaveOps\n    save = self.save_op(filename_tensor, vars_to_save)\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 165, in save_op\n    tensor_slices=[vs.slice_spec for vs in vars_to_save])\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/io_ops.py\", line 179, in _save\n    tensors, name=name)\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 438, in _save_slices\n    data=data, name=name)\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 710, in apply_op\n    op_def=op_def)\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2317, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/holazhai/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1239, in __init__\n    self._traceback = _extract_stack()\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# DQN for CartPole in OpenAI Gym\n",
    "# Author: Flood Sung\n",
    "# Date: 2016.6.27\n",
    "# All rights reserved\n",
    "# -------------------------------\n",
    "\n",
    "import gym\n",
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "# Hyper Parameters for DQN\n",
    "GAMMA = 0.9 # discount factor for target Q \n",
    "INITIAL_EPSILON = 0.5 # starting value of epsilon\n",
    "FINAL_EPSILON = 0.01 # final value of epsilon\n",
    "REPLAY_SIZE = 10000 # experience replay buffer size\n",
    "BATCH_SIZE = 32 # size of minibatch\n",
    "\n",
    "class DQN():\n",
    "\t# DQN Agent\n",
    "\tdef __init__(self, env):\n",
    "\t\t# init experience replay\n",
    "\t\tself.replay_buffer = deque()\n",
    "\t\t# init some parameters\n",
    "\t\tself.time_step = 0\n",
    "\t\tself.epsilon = INITIAL_EPSILON\n",
    "\t\tself.state_dim = env.observation_space.shape[0]\n",
    "\t\tself.action_dim = env.action_space.n \n",
    "\n",
    "\t\tself.create_Q_network()\n",
    "\t\tself.create_training_method()\n",
    "\n",
    "\t\t# Init session\n",
    "\t\tself.session = tf.InteractiveSession()\n",
    "\t\tself.session.run(tf.initialize_all_variables())\n",
    "\n",
    "\t\t# loading networks\n",
    "\t\tself.saver = tf.train.Saver()\n",
    "\t\tcheckpoint = tf.train.get_checkpoint_state(\"saved_networks\")\n",
    "\t\tif checkpoint and checkpoint.model_checkpoint_path:\n",
    "\t\t\t\tself.saver.restore(self.session, checkpoint.model_checkpoint_path)\n",
    "\t\t\t\tprint \"Successfully loaded:\", checkpoint.model_checkpoint_path\n",
    "\t\telse:\n",
    "\t\t\t\tprint \"Could not find old network weights\"\n",
    "\n",
    "\t\tglobal summary_writer\n",
    "\t\tsummary_writer = tf.train.SummaryWriter('~/logs',graph=self.session.graph)\n",
    "\n",
    "\tdef create_Q_network(self):\n",
    "\t\t# network weights\n",
    "\t\tW1 = self.weight_variable([self.state_dim,20])\n",
    "\t\tb1 = self.bias_variable([20])\n",
    "\t\tW2 = self.weight_variable([20,self.action_dim])\n",
    "\t\tb2 = self.bias_variable([self.action_dim])\n",
    "\t\t# input layer\n",
    "\t\tself.state_input = tf.placeholder(\"float\",[None,self.state_dim])\n",
    "\t\t# hidden layers\n",
    "\t\th_layer = tf.nn.relu(tf.matmul(self.state_input,W1) + b1)\n",
    "\t\t# Q Value layer\n",
    "\t\tself.Q_value = tf.matmul(h_layer,W2) + b2\n",
    "\n",
    "\n",
    "\tdef create_training_method(self):\n",
    "\t\tself.action_input = tf.placeholder(\"float\",[None,self.action_dim]) # one hot presentation\n",
    "\t\tself.y_input = tf.placeholder(\"float\",[None])\n",
    "\t\tQ_action = tf.reduce_sum(tf.mul(self.Q_value,self.action_input),reduction_indices = 1)\n",
    "\t\tself.cost = tf.reduce_mean(tf.square(self.y_input - Q_action))\n",
    "\t\ttf.scalar_summary(\"loss\",self.cost)\n",
    "\t\tglobal merged_summary_op\n",
    "\t\tmerged_summary_op = tf.merge_all_summaries()\n",
    "\t\tself.optimizer = tf.train.AdamOptimizer(0.0001).minimize(self.cost)\n",
    "\n",
    "\tdef perceive(self,state,action,reward,next_state,done):\n",
    "\t\tone_hot_action = np.zeros(self.action_dim)\n",
    "\t\tone_hot_action[action] = 1\n",
    "\t\tself.replay_buffer.append((state,one_hot_action,reward,next_state,done))\n",
    "\t\tif len(self.replay_buffer) > REPLAY_SIZE:\n",
    "\t\t\tself.replay_buffer.popleft()\n",
    "\n",
    "\t\tif len(self.replay_buffer) > BATCH_SIZE:\n",
    "\t\t\tself.train_Q_network()\n",
    "\n",
    "\tdef train_Q_network(self):\n",
    "\t\tself.time_step += 1\n",
    "\t\t# Step 1: obtain random minibatch from replay memory\n",
    "\t\tminibatch = random.sample(self.replay_buffer,BATCH_SIZE)\n",
    "\t\tstate_batch = [data[0] for data in minibatch]\n",
    "\t\taction_batch = [data[1] for data in minibatch]\n",
    "\t\treward_batch = [data[2] for data in minibatch]\n",
    "\t\tnext_state_batch = [data[3] for data in minibatch]\n",
    "\n",
    "\t\t# Step 2: calculate y\n",
    "\t\ty_batch = []\n",
    "\t\tQ_value_batch = self.Q_value.eval(feed_dict={self.state_input:next_state_batch})\n",
    "\t\tfor i in range(0,BATCH_SIZE):\n",
    "\t\t\tdone = minibatch[i][4]\n",
    "\t\t\tif done:\n",
    "\t\t\t\ty_batch.append(reward_batch[i])\n",
    "\t\t\telse :\n",
    "\t\t\t\ty_batch.append(reward_batch[i] + GAMMA * np.max(Q_value_batch[i]))\n",
    "\n",
    "\t\tself.optimizer.run(feed_dict={\n",
    "\t\t\tself.y_input:y_batch,\n",
    "\t\t\tself.action_input:action_batch,\n",
    "\t\t\tself.state_input:state_batch\n",
    "\t\t\t})\n",
    "\t\tsummary_str = self.session.run(merged_summary_op,feed_dict={\n",
    "\t\t\t\tself.y_input : y_batch,\n",
    "\t\t\t\tself.action_input : action_batch,\n",
    "\t\t\t\tself.state_input : state_batch\n",
    "\t\t\t\t})\n",
    "\t\tsummary_writer.add_summary(summary_str,self.time_step)\n",
    "\n",
    "\t\t# save network every 1000 iteration\n",
    "\t\tif self.time_step % 1000 == 0:\n",
    "\t\t\tself.saver.save(self.session, 'saved_networks/' + 'network' + '-dqn', global_step = self.time_step)\n",
    "\n",
    "\tdef egreedy_action(self,state):\n",
    "\t\tQ_value = self.Q_value.eval(feed_dict = {\n",
    "\t\t\tself.state_input:[state]\n",
    "\t\t\t})[0]\n",
    "\t\tif random.random() <= self.epsilon:\n",
    "\t\t\treturn random.randint(0,self.action_dim - 1)\n",
    "\t\telse:\n",
    "\t\t\treturn np.argmax(Q_value)\n",
    "\n",
    "\t\tself.epsilon -= (INITIAL_EPSILON - FINAL_EPSILON)/10000\n",
    "\n",
    "\tdef action(self,state):\n",
    "\t\treturn np.argmax(self.Q_value.eval(feed_dict = {\n",
    "\t\t\tself.state_input:[state]\n",
    "\t\t\t})[0])\n",
    "\n",
    "\tdef weight_variable(self,shape):\n",
    "\t\tinitial = tf.truncated_normal(shape)\n",
    "\t\treturn tf.Variable(initial)\n",
    "\n",
    "\tdef bias_variable(self,shape):\n",
    "\t\tinitial = tf.constant(0.01, shape = shape)\n",
    "\t\treturn tf.Variable(initial)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Hyper Parameters\n",
    "ENV_NAME = 'CartPole-v0'\n",
    "EPISODE = 10000 # Episode limitation\n",
    "STEP = 300 # Step limitation in an episode\n",
    "TEST = 10 # The number of experiment test every 100 episode\n",
    "\n",
    "def main():\n",
    "\t# initialize OpenAI Gym env and dqn agent\n",
    "\tenv = gym.make(ENV_NAME)\n",
    "\tagent = DQN(env)\n",
    "\n",
    "\tfor episode in xrange(EPISODE):\n",
    "\t\t# initialize task\n",
    "\t\tstate = env.reset()\n",
    "\t\t# Train \n",
    "\t\tfor step in xrange(STEP):\n",
    "\t\t\taction = agent.egreedy_action(state) # e-greedy action for train\n",
    "\t\t\tnext_state,reward,done,_ = env.step(action)\n",
    "\t\t\t# Define reward for agent\n",
    "\t\t\treward_agent = -1 if done else 0.1\n",
    "\t\t\tagent.perceive(state,action,reward,next_state,done)\n",
    "\t\t\tstate = next_state\n",
    "\t\t\tif done:\n",
    "\t\t\t\tbreak\n",
    "\t\t# Test every 100 episodes\n",
    "\t\tif episode % 100 == 0:\n",
    "\t\t\ttotal_reward = 0\n",
    "\t\t\tfor i in xrange(TEST):\n",
    "\t\t\t\tstate = env.reset()\n",
    "\t\t\t\tfor j in xrange(STEP):\n",
    "\t\t\t\t\tenv.render()\n",
    "\t\t\t\t\taction = agent.action(state) # direct action for test\n",
    "\t\t\t\t\tstate,reward,done,_ = env.step(action)\n",
    "\t\t\t\t\ttotal_reward += reward\n",
    "\t\t\t\t\tif done:\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\t\tave_reward = total_reward/TEST\n",
    "\t\t\tprint 'episode: ',episode,'Evaluation Average Reward:',ave_reward\n",
    "\t\t\tif ave_reward >= 200:\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t# save results for uploading\n",
    "\tenv.monitor.start('gym_results/CartPole-v0-experiment-1',force = True)\n",
    "\tfor i in xrange(100):\n",
    "\t\tstate = env.reset()\n",
    "\t\tfor j in xrange(200):\n",
    "\t\t\tenv.render()\n",
    "\t\t\taction = agent.action(state) # direct action for test\n",
    "\t\t\tstate,reward,done,_ = env.step(action)\n",
    "\t\t\ttotal_reward += reward\n",
    "\t\t\tif done:\n",
    "\t\t\t\tbreak\n",
    "\tenv.monitor.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tmain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
