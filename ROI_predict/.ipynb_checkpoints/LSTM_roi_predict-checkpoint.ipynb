{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "timeLong = 30\n",
    "step = 20\n",
    "np.random.seed(2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logPathSortUniq = '/Users/holazhai/Documents/workspace/readshift/result_uniq_sort_ha_holaverse_int.log'\n",
    "colnameSortUniq = ['created_day', 'pdtid', 'pid','u','dt']\n",
    "dfSortUniq = pd.read_table(logPathSortUniq,sep='\\t',names=colnameSortUniq)\n",
    "dfSortUniq['key'] = zip(dfSortUniq['created_day'],dfSortUniq['pdtid'],dfSortUniq['pid'],dfSortUniq['u'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getDfDic(dfSortUniq):\n",
    "    dfDic = {}\n",
    "    for index, row in dfSortUniq.iterrows():\n",
    "        key = row['key']\n",
    "        value = row['dt']\n",
    "        #print key,value\n",
    "        if dfDic.has_key(key):\n",
    "            dfDic[key].append(value)\n",
    "        else:\n",
    "            dfDic[key]=[value]\n",
    "    return dfDic\n",
    "dfDic=getDfDic(dfSortUniq)\n",
    "\n",
    "import datetime\n",
    "def plusDay(strTime):\n",
    "    time1 = datetime.datetime.strptime(strTime,'%Y-%m-%d')\n",
    "    next_dat = time1 + datetime.timedelta(hours = 24)\n",
    "    next_str = datetime.datetime.strftime(next_dat,'%Y-%m-%d')\n",
    "    return str(next_str)\n",
    "\n",
    "def diffDay(day1,day2):\n",
    "    d1=datetime.datetime.strptime(day1,'%Y-%m-%d')\n",
    "    d2=datetime.datetime.strptime(day2,'%Y-%m-%d')\n",
    "    return (d1-d2).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getDfListKeyAndValue(dfDic):\n",
    "    dfListKey = []\n",
    "    dfListValue = []\n",
    "    for key in dfDic.keys():\n",
    "        l = dfDic[key]\n",
    "        ltempKey = []\n",
    "        ltempValue = []\n",
    "        times = key[0]\n",
    "    \n",
    "        if times in l:\n",
    "            l.remove(times)\n",
    "        \n",
    "        if len(l)==0:\n",
    "            pass;\n",
    "        else:\n",
    "            #print l,times,plusDay(times),diffDay(plusDay(times),times)\n",
    "            ltempKey.append(key)\n",
    "            for i in range(len(l)):\n",
    "                diff = diffDay(l[i],times)\n",
    "                times = l[i]\n",
    "                for i in range(diff-1):\n",
    "                    ltempValue.append(0)\n",
    "                ltempValue.append(1)\n",
    "            if len(ltempValue)<timeLong:\n",
    "                for i in range(timeLong-len(ltempValue)):\n",
    "                    ltempValue.append(0)\n",
    "            #print ltempKey,ltempValue\n",
    "            dfListKey.append(ltempKey)\n",
    "            dfListValue.append(ltempValue)\n",
    "            \n",
    "    return dfListKey,dfListValue\n",
    "dfListKey,dfListValue = getDfListKeyAndValue(dfDic)\n",
    "            \n",
    "print len(dfListValue)\n",
    "print len(dfListKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfArrayKey=[]\n",
    "dfArrayValue =[]\n",
    "length = len(dfListKey)\n",
    "\n",
    "for i in range(length):\n",
    "    for j in range(timeLong-step-1):\n",
    "        #取五分之一的负样本,为了样本平衡\n",
    "        if dfListValue[i][j+step] == 0:\n",
    "            if np.random.random() >0.80:\n",
    "                dfArrayValue.append(dfListValue[i][j:j+step+1])\n",
    "                dfArrayKey.append(dfListKey[i])\n",
    "        else:\n",
    "            dfArrayValue.append(dfListValue[i][j:j+step+1])\n",
    "            dfArrayKey.append(dfListKey[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train = np.array(dfArrayValue)[:,0:step]\n",
    "y_train = np.array(dfArrayValue)[:,step] \n",
    "x_train = x_train.reshape(x_train.shape[0],1,step)\n",
    "print x_train.shape\n",
    "print y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train NN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, TimeDistributed\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(32,input_shape=(1,step)))\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dense(1,activation='relu'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Train...')\n",
    "model.fit(x_train, y_train, batch_size=64, nb_epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#存在问题，正负样本数目不一致\n",
    "y_train\n",
    "a = np.array(filter(lambda x: x > 0, y_train))\n",
    "print len(a)\n",
    "print len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39932, 1, 20)\n",
      "(10000, 1, 20)\n",
      "(39932,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "x1=x_train[0:-5000][:][:]\n",
    "print x1.shape\n",
    "x2=x_train[-5000:][:][:]\n",
    "print x2.shape\n",
    "y1=y_train[0:-5000][:]\n",
    "print y1.shape\n",
    "y2=y_train[-5000:][:]\n",
    "print y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(LSTM(64,input_shape=(1,step),return_sequences=True))\n",
    "model2.add(LSTM(32))\n",
    "model2.add(Dense(32,activation='relu'))\n",
    "model2.add(Dense(1,activation='relu'))\n",
    "\n",
    "model2.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 39932 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "39932/39932 [==============================] - 7s - loss: 0.2721 - acc: 0.9056 - val_loss: 0.2592 - val_acc: 0.9066\n",
      "Epoch 2/5\n",
      "31360/39932 [======================>.......]"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-af57441d23fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/holazhai/anaconda/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/Users/holazhai/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1104\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[1;32m   1107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/holazhai/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[1;32m    828\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# last batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/holazhai/anaconda/lib/python2.7/site-packages/keras/callbacks.pyc\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mt_before_callbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/holazhai/anaconda/lib/python2.7/site-packages/keras/callbacks.pyc\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;31m# will be handled by on_epoch_end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nb_sample'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/holazhai/anaconda/lib/python2.7/site-packages/keras/utils/generic_utils.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values, force)\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0minfo\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_total_width\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_width\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/holazhai/anaconda/lib/python2.7/site-packages/ipykernel/iostream.pyc\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                 \u001b[0;31m# newlines imply flush in subprocesses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file"
     ]
    }
   ],
   "source": [
    "print('Train...')\n",
    "model2.fit(x1, y1, batch_size=32, nb_epoch=5,shuffle=True,validation_data=(x2, y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "y2_p=model2.predict(x2)\n",
    "testScore = math.sqrt(mean_squared_error(y2, y2_p))\n",
    "print testScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#LSTM For Regression with Time Steps\n",
    "xx1=x1.reshape(x1.shape[0],x1.shape[2],x1.shape[1])\n",
    "print xx1.shape\n",
    "yy1=y1\n",
    "xx2=x2.reshape(x2.shape[0],x2.shape[2],x2.shape[1])\n",
    "yy2=y2\n",
    "print xx2.shape\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(LSTM(64,input_shape=(step,1),return_sequences=True))\n",
    "model3.add(LSTM(64))\n",
    "model3.add(Dense(32,activation='tanh'))\n",
    "model3.add(Dense(1,activation='tanh'))\n",
    "\n",
    "model3.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Train...')\n",
    "model3.fit(xx1, yy1, batch_size=64, nb_epoch=20,shuffle=True,validation_data=(xx2, yy2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#LSTM With Memory Between Batches\n",
    "#http://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\n",
    "#验证留存率计算结果\n",
    "#2016-07-24600004ha_holaverse_int 28742\n",
    "print len(dfArrayKey)\n",
    "print type(dfArrayKey)\n",
    "print len(dfArrayValue)\n",
    "print type(dfArrayValue)\n",
    "#选择测试数据 2016-06-06#600001#Organic_up\n",
    "\n",
    "print type(dfListKey)\n",
    "print dfListKey[0][0]\n",
    "print dfListValue[0]\n",
    "print len(dfListValue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfArrayKeyTest=[]\n",
    "dfArrayValueTest =[]\n",
    "length = len(dfListKey)\n",
    "for i in range(length):\n",
    "    keyTimes = dfListKey[i][0][0]\n",
    "    proid = dfListKey[i][0][1]\n",
    "    pid = dfListKey[i][0][2]\n",
    "    if keyTimes=='2016-07-25' and proid==600004 and pid=='ha_holaverse_int':\n",
    "        dfArrayValueTest.append(dfListValue[i][0:step+1])\n",
    "        dfArrayKeyTest.append(dfListKey[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testX = np.array(dfArrayValueTest)[:,0:step]\n",
    "testY = np.array(dfArrayValueTest)[:,step] \n",
    "print testX.shape\n",
    "testX = testX.reshape(testX.shape[0],step,1)\n",
    "print testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictTestX = model3.predict(testX)\n",
    "pos = np.where(predictTestX>0.8)\n",
    "print len(pos[0])\n",
    "print sum(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictTestX = model.predict(testX.reshape(testX.shape[0],testX.shape[2],testX.shape[1]))\n",
    "pos = np.where(predictTestX>0.8)\n",
    "print len(pos[0])\n",
    "print sum(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictTestX = model2.predict(testX.reshape(testX.shape[0],testX.shape[2],testX.shape[1]))\n",
    "pos = np.where(predictTestX>0.8)\n",
    "print len(pos[0])\n",
    "print sum(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#测试过程\n",
    "logPathSortUniq20160801 = '/Users/holazhai/Documents/workspace/readshift/result_uniq_sort_20160801.log'\n",
    "colnameSortUniq20160801 = ['created_day', 'pdtid', 'pid','u','dt']\n",
    "dfSortUniq20160801 = pd.read_table(logPathSortUniq20160801,sep='\\t',names=colnameSortUniq20160801)\n",
    "\n",
    "dfSortUniq20160801['key'] = zip(dfSortUniq20160801['created_day'],dfSortUniq20160801['pdtid'],dfSortUniq20160801['pid'],dfSortUniq20160801['u'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfDic20160801=getDfDic(dfSortUniq20160801)\n",
    "dfListKey20160801,dfListValue20160801 = getDfListKeyAndValue(dfDic20160801)\n",
    "print len(dfListKey20160801)\n",
    "print len(dfListValue20160801)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfArrayKeyTest20160801=[]\n",
    "dfArrayValueTest20160801 =[]\n",
    "length = len(dfListKey20160801)\n",
    "print length\n",
    "for i in range(length):\n",
    "    keyTimes = dfListKey20160801[i][0][0]\n",
    "    proid = dfListKey20160801[i][0][1]\n",
    "    pid = dfListKey20160801[i][0][2]\n",
    "    if keyTimes=='2016-08-04' and proid==600004 and pid=='ha_holaverse_int':\n",
    "        #print dfListValue20160801[i][0:21]\n",
    "        dfArrayValueTest20160801.append(dfListValue20160801[i][0:21])\n",
    "        dfArrayKeyTest20160801.append(dfListKey20160801[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testX = np.array(dfArrayValueTest20160801)[:,0:step]\n",
    "testY = np.array(dfArrayValueTest20160801)[:,step] \n",
    "print testX.shape\n",
    "testX = testX.reshape(testX.shape[0],step,1)\n",
    "print testX.shape\n",
    "predictTestX = model3.predict(testX)\n",
    "pos = np.where(predictTestX>0.8)\n",
    "print \"model3:\"\n",
    "print len(pos[0])\n",
    "print sum(testY)\n",
    "predictTestX = model.predict(testX.reshape(testX.shape[0],testX.shape[2],testX.shape[1]))\n",
    "pos = np.where(predictTestX>0.8)\n",
    "print \"model:\"\n",
    "print len(pos[0])\n",
    "print sum(testY)\n",
    "predictTestX = model2.predict(testX.reshape(testX.shape[0],testX.shape[2],testX.shape[1]))\n",
    "pos = np.where(predictTestX>0.8)\n",
    "print \"model2:\"\n",
    "print len(pos[0])\n",
    "print sum(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
